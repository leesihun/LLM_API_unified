# Hoonbot

A simplified, tool-driven personal AI assistant that connects Huni Messenger (chat UI) with LLM_API_fast (LLM backend).

## Quick Start

### Prerequisites

1. **LLM_API_fast running:**
   ```bash
   cd ../LLM_API_fast
   python tools_server.py &      # Terminal 1
   python run_backend.py &       # Terminal 2
   ```

2. **Huni Messenger running on port 3000**

### Setup (One-Time)

Run the setup script to automatically obtain LLM credentials:

```bash
cd Hoonbot
python setup.py
```

This will:
- Connect to LLM_API_fast at http://localhost:10007
- Login with default credentials (admin/administrator)
- Fetch available models
- Save token to `data/.llm_key`
- Save model to `data/.llm_model`

Example output:
```
============================================================
  Hoonbot Setup
============================================================

[Setup] Connecting to LLM_API_fast at http://localhost:10007
[OK] Successfully obtained access token

Fetching available models...

Available models:
  1. claude-opus-4-6
  2. claude-sonnet-4-6
  3. claude-haiku-4-5

Selected: claude-opus-4-6

Saving credentials...
[OK] Saved LLM_API_KEY to data/.llm_key
[OK] Saved LLM_MODEL to data/.llm_model

============================================================
  Setup Complete!
============================================================

Credentials saved to:
  data/.llm_key    (API token)
  data/.llm_model  (Model name)

You can now start Hoonbot:
  python hoonbot.py

No environment variables needed!
```

### Start Hoonbot

```bash
cd Hoonbot
python hoonbot.py
```

**No environment variables needed!** Credentials are loaded from:
- `data/.llm_key` â€” LLM API token
- `data/.llm_model` â€” Model name

Expected output:
```
[Messenger] Bot registered and key saved
[Messenger] Webhook target: http://localhost:3939/webhook
[Hoonbot] Ready on port 3939
```

## Key Documentation

### ğŸ“‹ [PROMPT.md](PROMPT.md) â€” System Prompt
The unified prompt that tells the LLM how to behave, what tools to use, and how to manage memory.

**Key sections:**
- Identity and behavior guidelines
- Memory system instructions (read/write)
- Complete tool documentation
- When to update memory
- Webhook handling guidelines

**Automatically loaded and injected into every LLM call.**

### ğŸ—ï¸ [ARCHITECTURE.md](ARCHITECTURE.md) â€” System Design
Complete technical documentation explaining how Hoonbot works.

**Key sections:**
- System diagrams and data flow
- Component descriptions
- File organization
- Configuration reference
- Startup sequence
- Troubleshooting guide

**Read this to understand how everything connects.**

### ğŸ§  [data/memory.md](data/memory.md) â€” Persistent Memory
Single memory file where information persists across conversations.

**Features:**
- Plain Markdown format
- Automatically injected into every LLM prompt
- Absolute path provided to LLM
- Can be edited manually or via file_writer tool

**The LLM uses file_reader to read and file_writer to update.**

## How It Works

### 1. User sends message in Messenger
```
User â†’ Messenger (port 3000) â†’ Hoonbot (port 3939)
```

### 2. Hoonbot processes the message
```
1. Load PROMPT.md (system prompt)
2. Load data/memory.md (persistent memory)
3. Get absolute path to memory file
4. Call LLM_API_fast with agent_type: auto
```

### 3. LLM uses tools to accomplish the task
```
Available tools:
- file_reader      : Read memory and other files
- file_writer      : Update memory and save files
- file_navigator   : Explore directories
- websearch        : Search the web
- python_coder     : Run Python code
- rag              : Query documents
- shell_exec       : Run shell commands
```

### 4. LLM returns response to Hoonbot
```
LLM response â†’ Hoonbot â†’ Messenger (port 3000) â†’ User
```

## File Structure

```
Hoonbot/
â”œâ”€â”€ README.md                â† Start here
â”œâ”€â”€ ARCHITECTURE.md          â† Technical design
â”œâ”€â”€ PROMPT.md               â† System prompt (unified)
â”œâ”€â”€ SOUL.md                 â† Personality reference (included in PROMPT.md)
â”‚
â”œâ”€â”€ hoonbot.py              # Main entry point
â”œâ”€â”€ config.py               # Configuration
â”œâ”€â”€ setup.py                # Setup script (automatic credential management)
â”œâ”€â”€ test_llm.py             # Test script
â”œâ”€â”€ reset.py                # Memory reset utility
â”‚
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ webhook.py          # Message processing
â”‚   â””â”€â”€ health.py           # Health check endpoint
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ messenger.py        # Messenger API client
â”‚   â””â”€â”€ retry.py            # Retry decorator
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ memory.md           # Persistent memory (auto-injected)
    â”œâ”€â”€ .llm_key            # LLM API token (created by setup.py)
    â”œâ”€â”€ .llm_model          # LLM model name (created by setup.py)
    â””â”€â”€ .apikey             # Messenger API key (auto-created)
```

## Configuration

All settings via environment variables in `config.py`:

```bash
# Server
HOONBOT_PORT=3939
HOONBOT_HOST=0.0.0.0

# Messenger
MESSENGER_PORT=3000
HOONBOT_BOT_NAME=Hoonbot
HOONBOT_HOME_ROOM_ID=1

# LLM_API_fast (loaded from files, not env vars)
# Credentials: setup.py saves to data/.llm_key and data/.llm_model
LLM_API_PORT=10007
LLM_API_URL=http://localhost:10007  # Can override with env var

# Webhooks (optional)
HOONBOT_WEBHOOK_SECRET=optional_secret_for_incoming_webhooks
```

## Memory System

### How It Works

1. `data/memory.md` is a plain Markdown file
2. On every LLM call, memory content is injected into the system prompt
3. LLM's absolute path to the file is also provided
4. LLM can read the file with `file_reader` tool
5. LLM can update the file with `file_writer` tool

### What to Save

- User preferences and personal information
- Important facts and decisions
- Project status
- Anything the user says to remember

### Example Update Flow

```
User: "Remember: I'm working on Project X"
     â†“
LLM sees this in conversation
     â†“
LLM uses file_reader to read current memory.md
     â†“
LLM adds "Project X" entry to memory
     â†“
LLM uses file_writer to save updated memory.md
     â†“
Next message includes updated memory
```

### Manual Editing

Edit `data/memory.md` directly in any text editor:
```markdown
# Hoonbot Memory

## User
- Name: Huni
- Language: Korean
- Preferences: [list preferences]

## Projects
- [Project info]

## Notes
- [Important facts]
```

## Tool System

Everything works through LLM_API_fast tools. The LLM automatically decides which tool to use:

- **Need to save information?** â†’ Use file_writer
- **Need to check saved info?** â†’ Use file_reader
- **Need to search the web?** â†’ Use websearch
- **Need to analyze data?** â†’ Use python_coder
- **Need to run a command?** â†’ Use shell_exec

**No custom commands or parsingâ€”just pure tool usage.**

## Webhook Events

External services can trigger Hoonbot by posting to:
```
POST http://localhost:3939/webhook/incoming/<source>
X-Webhook-Secret: optional_secret (if configured)
Content-Type: application/json

{
  "message": "Something happened"
}
```

Example: GitHub webhook
```
POST http://localhost:3939/webhook/incoming/github
Content-Type: application/json

{
  "action": "opened",
  "pull_request": {
    "title": "Fix bug in auth",
    "url": "..."
  }
}
```

Hoonbot receives: `[Webhook from github] PR opened: Fix bug in auth...`

## Testing

### Test LLM Connection

```bash
python test_llm.py
```

Tests if:
- LLM_API_fast is reachable
- Credentials are properly configured
- LLM responds to messages
- Memory file is accessible

### Reset Memory

```bash
# View current memory
python reset.py --view-memory

# Clear memory (keeps file, makes empty)
python reset.py --memory

# Reset everything (memory, APIkey, etc)
python reset.py --all
```

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Huni Messenger (TypeScript/Electron)   â”‚
â”‚  Chat UI on port 3000                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP: POST /webhook
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hoonbot (Python/FastAPI)               â”‚
â”‚  Main entry: hoonbot.py                 â”‚
â”‚  Processing: handlers/webhook.py        â”‚
â”‚  Port: 3939                             â”‚
â”‚                                         â”‚
â”‚  1. Receive message from Messenger      â”‚
â”‚  2. Load PROMPT.md + memory.md          â”‚
â”‚  3. Get absolute memory path            â”‚
â”‚  4. Call LLM_API_fast                   â”‚
â”‚  5. LLM uses tools automatically        â”‚
â”‚  6. Send reply back to Messenger        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ HTTP: POST /v1/chat/completions
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM_API_fast (Python/FastAPI)          â”‚
â”‚  Agent System on port 10007             â”‚
â”‚                                         â”‚
â”‚  Tools Available:                       â”‚
â”‚  â€¢ file_reader / file_writer            â”‚
â”‚  â€¢ file_navigator                       â”‚
â”‚  â€¢ websearch                            â”‚
â”‚  â€¢ python_coder                         â”‚
â”‚  â€¢ rag                                  â”‚
â”‚  â€¢ shell_exec                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Troubleshooting

### Setup fails: "Cannot connect to LLM_API_fast"

Make sure LLM_API_fast is running:
```bash
ps aux | grep run_backend
```

Check the port matches in setup.py (default: http://localhost:10007)

### "LLM_API_KEY is not configured"

Run setup.py to create credentials:
```bash
python setup.py
```

Check that files were created:
```bash
ls -la data/.llm_key data/.llm_model
```

### Memory not updating

The LLM might not be using the file_writer tool:

1. Check PROMPT.md has clear memory update instructions
2. Run `python test_llm.py` to test LLM functionality
3. Check LLM_API_fast logs for tool execution errors
4. Try manually editing `data/memory.md` to verify file is writable

### Bot not responding

General troubleshooting:

1. Check all services are running:
   ```bash
   ps aux | grep -E "(run_backend|npm|hoonbot)"
   ```

2. Check logs:
   ```bash
   tail -f logs/hoonbot.log
   ```

3. Test with simple message in Messenger

4. Verify configuration in `config.py`

## Development

### Add New Capability

Since everything uses LLM_API_fast tools, new capabilities are added by:

1. Update PROMPT.md with new instructions/guidelines
2. LLM automatically uses appropriate tools
3. No code changes needed

Example: To add CSV analysis
- Just mention in PROMPT.md that LLM can use python_coder for CSV files
- LLM will automatically use that tool when needed

### Modify Memory Format

Edit `data/memory.md` directly or update PROMPT.md with new guidance. No code changes needed.

### Add New Webhook Source

No code changesâ€”just POST to `/webhook/incoming/<source>` and Hoonbot handles it.

## Performance Tips

1. **Keep memory.md reasonably sized** â€” It's included in every prompt
2. **Use file_navigator** â€” Don't guess file paths, use the tool to explore
3. **Set reasonable timeouts** â€” Especially for long-running tasks
4. **Monitor token usage** â€” Memory size affects API costs

## Security

- **LLM API Key:** Stored in `data/.llm_key`, never commit to git
- **Messenger API Key:** Stored in `data/.apikey`, keep secret
- **Webhook Secret:** Use for external integrations to verify authenticity
- **File Access:** LLM has access to files via toolsâ€”be careful with sensitive paths
- **Code Execution:** python_coder runs arbitrary codeâ€”validate user requests first

## Support

Check these files in order:

1. **ARCHITECTURE.md** â€” How does the system work?
2. **PROMPT.md** â€” What are the LLM guidelines?
3. **config.py** â€” Is it configured correctly?
4. **test_llm.py** â€” Can we reach the LLM?
5. **Logs** â€” What errors are in logs/?

## License & Credits

Hoonbot â€” Simplified AI Assistant for Huni

---

**Last Updated:** 2026-02-26
**Version:** 1.0 (Simplified Tool-Driven Architecture)
